{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ludoveltz/test_github_fev25/blob/main/Daily_challenge_day4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zN8uEFm2Ti4-",
        "outputId": "d40c77b9-efc8-4280-e857-2e5c855de0cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "pip install torch torchvision torchaudio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SAHbYqwU4A7",
        "outputId": "bcc6ab92-90ba-4d94-a6c9-b7dc4957ee02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Contenu du Drive :\n",
            "['household_power_consumption.txt', 'metadata.csv', 'Data', 'Colab Notebooks']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Afficher le contenu du Drive\n",
        "print(\"Contenu du Drive :\")\n",
        "print(os.listdir('/content/drive/My Drive'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3g9RI54UbU9",
        "outputId": "27dd8cb1-f503-4a16-ac22-3a54d4429ff4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Aperçu des données après correction :\n",
            "   Global_active_power  Global_reactive_power  Voltage  Global_intensity  \\\n",
            "0                4.216                  0.418   234.84              18.4   \n",
            "1                5.360                  0.436   233.63              23.0   \n",
            "2                5.374                  0.498   233.29              23.0   \n",
            "3                5.388                  0.502   233.74              23.0   \n",
            "4                3.666                  0.528   235.68              15.8   \n",
            "\n",
            "   Sub_metering_1  Sub_metering_2  Sub_metering_3            datetime  target  \n",
            "0             0.0             1.0            17.0 2006-12-16 17:24:00   5.360  \n",
            "1             0.0             1.0            16.0 2006-12-16 17:25:00   5.374  \n",
            "2             0.0             2.0            17.0 2006-12-16 17:26:00   5.388  \n",
            "3             0.0             1.0            17.0 2006-12-16 17:27:00   3.666  \n",
            "4             0.0             1.0            17.0 2006-12-16 17:28:00   3.520  \n",
            "\n",
            "Informations sur le dataset :\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 2075258 entries, 0 to 2075257\n",
            "Data columns (total 9 columns):\n",
            " #   Column                 Dtype         \n",
            "---  ------                 -----         \n",
            " 0   Global_active_power    float64       \n",
            " 1   Global_reactive_power  float64       \n",
            " 2   Voltage                float64       \n",
            " 3   Global_intensity       float64       \n",
            " 4   Sub_metering_1         float64       \n",
            " 5   Sub_metering_2         float64       \n",
            " 6   Sub_metering_3         float64       \n",
            " 7   datetime               datetime64[ns]\n",
            " 8   target                 float64       \n",
            "dtypes: datetime64[ns](1), float64(8)\n",
            "memory usage: 158.3 MB\n",
            "None\n",
            "\n",
            "Aperçu des données normalisées :\n",
            "   Global_active_power  Global_reactive_power   Voltage  Global_intensity  \\\n",
            "0             0.374796               0.300719  0.376090          0.377593   \n",
            "1             0.478363               0.313669  0.336995          0.473029   \n",
            "2             0.479631               0.358273  0.326010          0.473029   \n",
            "3             0.480898               0.361151  0.340549          0.473029   \n",
            "4             0.325005               0.379856  0.403231          0.323651   \n",
            "\n",
            "   Sub_metering_1  Sub_metering_2  Sub_metering_3    target  \n",
            "0             0.0          0.0125        0.548387  0.478363  \n",
            "1             0.0          0.0125        0.516129  0.479631  \n",
            "2             0.0          0.0250        0.548387  0.480898  \n",
            "3             0.0          0.0125        0.548387  0.325005  \n",
            "4             0.0          0.0125        0.548387  0.311787  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Chemin correct vers le fichier (directement à la racine du Drive)\n",
        "chemin = \"/content/drive/My Drive/household_power_consumption.txt\"\n",
        "\n",
        "try:\n",
        "    # Première lecture sans parse_dates\n",
        "    df = pd.read_csv(chemin,\n",
        "                     sep=';',\n",
        "                     na_values=['?'])\n",
        "\n",
        "    # Création de la colonne datetime après la lecture\n",
        "    df['datetime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'],\n",
        "                                  format='%d/%m/%Y %H:%M:%S')\n",
        "\n",
        "    # Suppression des colonnes Date et Time originales\n",
        "    df = df.drop(['Date', 'Time'], axis=1)\n",
        "\n",
        "    # Utilisation de ffill() pour les valeurs manquantes\n",
        "    df = df.ffill()\n",
        "\n",
        "    # Conversion des colonnes en type float\n",
        "    columns_to_convert = ['Global_active_power', 'Global_reactive_power',\n",
        "                         'Voltage', 'Global_intensity',\n",
        "                         'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3']\n",
        "\n",
        "    for col in columns_to_convert:\n",
        "        df[col] = df[col].astype(float)\n",
        "\n",
        "    # Création de la cible : consommation du jour suivant\n",
        "    df['target'] = df['Global_active_power'].shift(-1)\n",
        "    df = df.dropna()\n",
        "\n",
        "    # Normalisation des données\n",
        "    scaler = MinMaxScaler()\n",
        "    features = ['Global_active_power', 'Global_reactive_power',\n",
        "                'Voltage', 'Global_intensity',\n",
        "                'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3']\n",
        "\n",
        "    df_scaled = pd.DataFrame(scaler.fit_transform(df[features]), columns=features)\n",
        "    df_scaled['target'] = scaler.fit_transform(df[['target']])\n",
        "\n",
        "    # Affichage des résultats\n",
        "    print(\"Aperçu des données après correction :\")\n",
        "    print(df.head())\n",
        "    print(\"\\nInformations sur le dataset :\")\n",
        "    print(df.info())\n",
        "\n",
        "    print(\"\\nAperçu des données normalisées :\")\n",
        "    print(df_scaled.head())\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Erreur : Le fichier n'a pas été trouvé à l'emplacement : {chemin}\")\n",
        "except Exception as e:\n",
        "    print(f\"Une erreur s'est produite : {str(e)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "TM1QxmX5VcY1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import joblib\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# 3. Préparation des données\n",
        "class PowerConsumptionDataset(Dataset):\n",
        "    def __init__(self, data, sequence_length=24):\n",
        "        self.sequence_length = sequence_length\n",
        "        self.data = torch.FloatTensor(data)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) - self.sequence_length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        X = self.data[idx:idx + self.sequence_length]\n",
        "        y = self.data[idx + self.sequence_length, 0]  # Global_active_power\n",
        "        return X, y\n",
        "\n",
        "# Préparation des données\n",
        "def prepare_data(df, sequence_length=24):\n",
        "    # Normalisation\n",
        "    scaler = MinMaxScaler()\n",
        "    df_scaled = pd.DataFrame(\n",
        "        scaler.fit_transform(df),\n",
        "        columns=df.columns,\n",
        "        index=df.index\n",
        "    )\n",
        "\n",
        "    # Création des séquences\n",
        "    data = df_scaled.values\n",
        "\n",
        "    # Division des données\n",
        "    train_size = int(0.7 * len(data))\n",
        "    val_size = int(0.15 * len(data))\n",
        "\n",
        "    train_data = data[:train_size]\n",
        "    val_data = data[train_size:train_size+val_size]\n",
        "    test_data = data[train_size+val_size:]\n",
        "\n",
        "    # Création des datasets\n",
        "    train_dataset = PowerConsumptionDataset(train_data, sequence_length)\n",
        "    val_dataset = PowerConsumptionDataset(val_data, sequence_length)\n",
        "    test_dataset = PowerConsumptionDataset(test_data, sequence_length)\n",
        "\n",
        "    # Création des dataloaders\n",
        "    batch_size = 32\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "    return train_loader, val_loader, test_loader, scaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mGrLKyZLVqWT"
      },
      "outputs": [],
      "source": [
        "# 4. Définition du modèle LSTM\n",
        "class HybridModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size=64):\n",
        "        super(HybridModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=2,\n",
        "            batch_first=True,\n",
        "            dropout=0.2\n",
        "        )\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=hidden_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=2,\n",
        "            batch_first=True,\n",
        "            dropout=0.2\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        gru_out, _ = self.gru(lstm_out)\n",
        "        out = self.fc(gru_out[:, -1, :])\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "fXAXjhBnfxCa"
      },
      "outputs": [],
      "source": [
        "# 5. Entraînement du modèle\n",
        "def train_model(model, train_loader, val_loader, num_epochs=20):\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = model.to(device)\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    progress_bar = tqdm(range(num_epochs), desc='Entraînement')\n",
        "\n",
        "    for epoch in progress_bar:\n",
        "        # Phase d'entraînement\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for X, y in train_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X)\n",
        "            loss = criterion(outputs.squeeze(), y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        # Phase de validation\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for X, y in val_loader:\n",
        "                X, y = X.to(device), y.to(device)\n",
        "                outputs = model(X)\n",
        "                val_loss += criterion(outputs.squeeze(), y).item()\n",
        "\n",
        "        # Calcul des pertes moyennes\n",
        "        avg_train_loss = train_loss/len(train_loader)\n",
        "        avg_val_loss = val_loss/len(val_loader)\n",
        "\n",
        "        train_losses.append(avg_train_loss)\n",
        "        val_losses.append(avg_val_loss)\n",
        "\n",
        "        # Mise à jour de la barre de progression\n",
        "        progress_bar.set_postfix({\n",
        "            'train_loss': f'{avg_train_loss:.4f}',\n",
        "            'val_loss': f'{avg_val_loss:.4f}'\n",
        "        })\n",
        "\n",
        "    return model, train_losses, val_losses\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "6ExfEHqiV3VE"
      },
      "outputs": [],
      "source": [
        "# 6. Évaluation du modèle\n",
        "def evaluate_model(model, test_loader, scaler):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    actuals = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in test_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            outputs = model(X)\n",
        "            predictions.extend(outputs.cpu().numpy())\n",
        "            actuals.extend(y.cpu().numpy())\n",
        "\n",
        "    # Calcul du R²\n",
        "    r2 = r2_score(actuals, predictions)\n",
        "    print(f'Score R² : {r2:.4f}')\n",
        "\n",
        "    # Sauvegarde du scaler\n",
        "    joblib.dump(scaler, 'power_consumption_scaler.joblib')\n",
        "\n",
        "    return predictions, actuals\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXZqrapmV5FD",
        "outputId": "5928aaa2-5806-4824-b81a-fa7e406f4f88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Début de l'entraînement...\n",
            "\n",
            "Epoch 1/10\n",
            "[==============================] - 100.0% - loss: 0.0003\n",
            "Epoch 2/10\n",
            "[==============================] - 100.0% - loss: 0.0004\n",
            "Epoch 3/10\n",
            "[==============================] - 100.0% - loss: 0.0020\n",
            "Epoch 4/10\n",
            "[==============================] - 100.0% - loss: 0.0001\n",
            "Epoch 5/10\n",
            "[==============================] - 100.0% - loss: 0.0000\n",
            "Epoch 6/10\n",
            "[==============================] - 100.0% - loss: 0.0012\n",
            "Epoch 7/10\n",
            "[==============================] - 100.0% - loss: 0.0007\n",
            "Epoch 8/10\n",
            "[==============================] - 100.0% - loss: 0.0042\n",
            "Epoch 9/10\n",
            "[==============================] - 100.0% - loss: 0.0014\n",
            "Epoch 10/10\n",
            "[==============================] - 100.0% - loss: 0.0008Score R² : 0.9504\n",
            "\n",
            "Prédiction pour le prochain jour : 0.56 kW\n"
          ]
        }
      ],
      "source": [
        "# 7. Prédictions futures\n",
        "def predict_next_day(model, last_sequence, scaler):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Préparation des données\n",
        "        sequence = torch.FloatTensor(last_sequence).unsqueeze(0)\n",
        "        # Prédiction\n",
        "        prediction = model(sequence)\n",
        "        # Inverse transform\n",
        "        prediction = prediction.numpy()\n",
        "        prediction_original = scaler.inverse_transform(\n",
        "            np.concatenate([prediction, np.zeros((len(prediction), 6))], axis=1)\n",
        "        )[:, 0]\n",
        "    return prediction_original[0]\n",
        "\n",
        "# Utilisation du code\n",
        "if __name__ == \"__main__\":\n",
        "    # Configuration\n",
        "    num_epochs = 10  # Défini ici pour Google Colab\n",
        "\n",
        "    # Chargement des données\n",
        "    chemin = \"/content/drive/My Drive/household_power_consumption.txt\"\n",
        "    df = pd.read_csv(chemin, sep=';', na_values=['?'])\n",
        "\n",
        "    # Préparation des données avec correction des warnings\n",
        "    df['datetime'] = pd.to_datetime(\n",
        "        df['Date'] + ' ' + df['Time'],\n",
        "        format='%d/%m/%Y %H:%M:%S',\n",
        "        dayfirst=True\n",
        "    )\n",
        "    df = df.drop(['Date', 'Time'], axis=1)\n",
        "    df = df.set_index('datetime')\n",
        "    df = df.ffill()  # Utilisation de ffill() au lieu de fillna(method='ffill')\n",
        "\n",
        "    # Création des datasets et du modèle\n",
        "    train_loader, val_loader, test_loader, scaler = prepare_data(df)\n",
        "    model = HybridModel(input_size=7)  # 7 features\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    # Entraînement avec barre de progression style Keras\n",
        "    print(\"Début de l'entraînement...\")\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
        "\n",
        "        for batch_idx, (X, y) in enumerate(train_loader):\n",
        "            # Affichage de la progression style Keras\n",
        "            progress = (batch_idx + 1) / len(train_loader)\n",
        "            bar_length = 30\n",
        "            filled_length = int(bar_length * progress)\n",
        "            bar = '=' * filled_length + '-' * (bar_length - filled_length)\n",
        "\n",
        "            # Training step\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X)\n",
        "            loss = criterion(outputs.squeeze(), y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Affichage de la progression avec la perte\n",
        "            print(f'\\r[{bar}] - {progress*100:.1f}% - loss: {loss.item():.4f}', end='')\n",
        "\n",
        "    # Évaluation\n",
        "    predictions, actuals = evaluate_model(model, test_loader, scaler)\n",
        "\n",
        "    # Exemple de prédiction future\n",
        "    last_sequence = next(iter(test_loader))[0][0].numpy()\n",
        "    next_day_prediction = predict_next_day(model, last_sequence, scaler)\n",
        "    print(f'\\nPrédiction pour le prochain jour : {next_day_prediction:.2f} kW')\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPOZchkOPBrLxPhvgqbafoc",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
